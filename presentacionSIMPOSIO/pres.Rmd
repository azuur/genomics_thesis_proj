---
title: "Assessment of Gene Regulatory Network Inference Algorithms Using Monte Carlo Simulations"
author: "Adrián Zuur and Liliana López-Kleine"
institute: "Department of Statistics, UNAL-Bogotá"
date: "July 19, 2019"
output:
  xaringan::moon_reader:
    css: ['default', 'default-fonts', 'hygge', 'azuur.css']
    lib_dir: libs
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
---

class:left 


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```


## What We Are Modeling

```{r, out.width = "1500px"}
knitr::include_graphics("image1.png")
```


---

class:left 

## The Mathematical Model

.pull-left[

Gene regulatory networks (GRNs) are models that aim to encode the regulatory relations among genes in a genome.

- Genes are nodes, regulatory relations are edges.
- Regulatory relations are *causal* (edges are directed, indicate more than co-expression).
- Edges represent *direct* causal effects (indirect effects are directed paths).

GRNs are directed graphs $(V,E)$, which are equivalent to an adjacency matrix.

]

.pull-right[
```{r, out.width = "400px"}
knitr::include_graphics("image2.png")
```
]



---

class:left 

## The Data

.pull-left[
The typical kind of data to learn GRNs is **gene expression data**, which are direct or indirect counts of mRNA.
.center[
```{r, out.width = "150px"}
knitr::include_graphics("image3.png")
```
]
Mostly, we have observational data, not experimental.



]

.pull-right[

```{r, out.width = "800px"}
knitr::include_graphics("image4.png")
```
]


---

class:left 


## The Statistical Problem
In bioinformatics there are many methods to build GRNs. 


Papers introducing them typically test them on given datasets. They show that the methods work *in practice*.


Our question is, *do they work well in theory?*

- How dependent is a method on shape of regulatory relations, sample size, noise, etc.?

- How reliable is the method? Are reported results flukes?






---
class:left 


## Methods We Study
.Mid[
.shorties[
.pull-left[
##### Mutual information-based
.small[


.content-box-gray[
##### Mutual information network
Estimate

$$I(X_i, X_j) = E\left(\log\frac{f_{X_i}(X_i)f_{X_j}(X_j) }{f_{X_iX_j}(X_i,X_j)}\right)$$

Filter edges from MI matrix with threshold.
]

.content-box-gray[
##### ARACNe
For each triplet of variables, eliminate edge with lowest estimated MI.
]
.content-box-gray[
##### MRNET
Derive 'minimum redundancy, maximum relevance' score from estimated MI using a step-wise procedure. Threshold.
]
.content-box-gray[
##### CLR
Standardize estimated MI matrix row-wise and column-wise. Average both scores. Threshold.

]
]
]

.pull-right[
##### Regression-based
.small[

.content-box-gray[
##### NARROMI

For each gene, estimate LAD-Lasso. Use coefficients as scores for edges. Threshold.

$$
\hat{\beta} =\text{argmin}_{\beta \in \mathbb{R}^p} |Y-\beta^{\top}X|+\lambda||\beta||_1
$$
]

.content-box-gray[
##### TIGRESS
For each gene, estimate Least Angle Regression (LARS) repeatedly in a bootstrap-like procedure. Use estimates to compute scores of relevance in prediction. Threshold.
]

.content-box-gray[
##### GENIE3
For each gene, estimate an ensemble of regression tress (e.g. random forest). Use estimates to compute scores of relevance in prediction. Threshold.
]
]
]
]
]
---

class:left 

## The Probabilistic Model to Estimate
.Small[These inference algorithms are heuristics. Consider them as estimators and look at their statistical properties (unfair).

Estimators of what? **A Bayesian Network associated to a causal SEM**.
]
.pull-left[
#### Causal Structural Equations Model (SEM)

.center[
```{r, out.width = "200px"}
knitr::include_graphics("image5.png")
```
]
.Small[
Each equation is a causal mechanism.

The joint distribution of noise variables $\epsilon_i$ determines a joint distribution of gene expressions. This is $P_X(x)$.
]
]

.pull-right[

#### Bayesian Network

.center[
```{r, out.width = "150px"}
knitr::include_graphics("image6.png")
```
]
.Small[
Assume joint independence of error variables (no unmeasured common causes), and aciclicity (no contemporary causation).

Draw an edge from direct causes to effects. This is a Bayesian Network, **our parameter of interest**.
]
]

---

class:left


## Side Note: On Causal Bayesian Networks


A Bayesian Network is related to the distribution $P_X(x)$ by a graphical notion called **d-separation**.

d-separation implies conditional statistical independence.

$$
X\perp_dY|Z \implies X\perp Y|Z
$$

Under an arguably weak condition, **faithfulness**, the converse also holds:

$$
X\perp Y|Z \implies X\perp_dY|Z
$$

In this case, the skeleton of the BN (that is, the undirected network it induces naturally) is identified. Estimation is possible but computationally complex.





---

class:left 

## Workflow


.left-column[
.Small[
1. Extract 50 node sub-network from "gold standard" *S. cerevisiae* GRN.

2. Generate causal SEMs over this network.

3. For each causal SEM, simulate 1000 datasets of size 20, 50, 100, and 500. Apply algorithms on datasets.

4. Evaluate algorithm outputs.
]
]
.center[
```{r, out.width = "460px"}
knitr::include_graphics("image7.png")
```

]






---

class:left 

## Sub-network

.left-column[

Sub-network extracted from "gold standard" GRN from Sisi Ma *et al.* (2014), using algorithm from Marbach *et al.* (2009). This algorithm maximizes modularity step-wise. Its output preserves some structural properties of its input.

]

.center[

```{r, out.width = "550px"}
knitr::include_graphics("image8.png")
```


]


---

class:left


## Causal SEM Definition

Eight cases, fixed coefficients $\alpha_{ij} \sim U(-1,1)$ throughout.


.pull-left[
* Functional form

$$f_i\left(pa\left(X_i\right), \varepsilon_i \right)=\sum_{X_j \in pa(X_i)} \alpha_{ij}X_j + \varepsilon_i$$


$$f_i\left(pa\left(X_i\right),  \varepsilon_i\right)=2\sigma\left( \sum_{X_j \in pa(X_i)} \alpha_{ij} X_j \right)-1 + \varepsilon_i$$



* Levels of noise

$$
FVU_i=\frac{Var(\varepsilon_i)}{Var(X_i)}=0.2
$$


$$
FVU_i=\frac{Var(\varepsilon_i)}{Var(X_i)}=0.8
$$

]


.pull-right[

* Distribution of error terms


$$
\varepsilon_{ij}\sim N(0,\sigma^2)
$$

$$
\varepsilon_{ij}\sim U(-b,b)
$$

]


---

class:left

## Estimation

.Small[
* Algorithms are used "out-of-the-box", that is, using parameters suggested by authors.

* Implementations by authors + reputable packages. NARROMI was translated from Matlab to R code.

* Mutual information was estimated with Miller-Madow estimator. Entropies and cross-entropies are estimated via maximum likelihood with discretized variables, plugged into definition of $I(X,Y)$, and a bias correction term is added.

$$\hat{H(}X)= - \sum_{b_X \in \text{bins}_X}\hat{p}_{b_X}\log\left(\hat{p}_{b_X}\right)$$
$$\hat{H(}Y)= - \sum_{b_Y \in \text{bins}_Y}\hat{p}_{b_Y}\log\left(\hat{p}_{b_Y}\right)$$

$$\hat{H(X,Y)}= - \sum_{b_{X \times Y} \in \text{bins}_{X\times Y}}\hat{p}_{b_{X\times Y}}\log\left(\hat{p}_{b_{X\times Y}}\right)$$

$$\hat{I(}X,Y)= \hat{H(}X)+\hat{H(}Y)-\hat{H(}X,Y) + \frac{\hat{m}-1}{n}$$

]

---

class:left 

## Assessment of Estimates

.pull-left[
.Small[
Each algorithm can be seen as a classifier that outputs scores $s_{ij}$ for edges. For each threshold on scores we get

$$
\text{Sens.} = \frac{\text{# correctly detected edges} }{\text{# true edges}}
$$

$$
\text{Spec.} = \frac{\text{# correctly detected non-edges} }{\text{# true non-edges}}
$$
Over all thresholds, we get a parametric curve - the ROC curve. The area under it, AUROC, is the probability that a randomly sampled true edge has a score higher than that of a  randomly sampled non-edge.
]
]

.pull-right[

```{r, out.width = "1000px"}
knitr::include_graphics("image9.png")
```

]

---

class:left

## Results

---

class:center

```{r, out.width = "800px"}
knitr::include_graphics("image10.png")
```


---

class:center

```{r, out.width = "800px"}
knitr::include_graphics("image11.gif")
```


---

class:left 


## Results

- MI-based algorithms are more variable than regression-based algorithms.

- MI-based algorithms are more sensitive to sample size than regression-based algorithms. ARACNe and NARROMI are the extremes.

- TIGRESS is most sensitive to $FVU$. ARACNe is least sensitive.

- Surprisingly good results for large $n$. Not so much for small $n$. 

- Better results with less noise, except at large sample size. Bias-variance trade-off.






---

class:left 

## Thanks

Thanks.

I'm interested in comments or suggestions.

My email is agzuurp@unal.edu.co, and we can talk outside.



---

class:left 

## References





